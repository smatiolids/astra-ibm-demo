{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "147c89b2",
   "metadata": {},
   "source": [
    "# IBM & DataStax Demo - Banking AI Agent\n",
    "\n",
    "## Before start\n",
    "\n",
    "Check the prereqs on the README.md file.\n",
    "\n",
    "## Part III - Agents and NoSQL\n",
    "\n",
    "- Create a CQL table to store banking transactions\n",
    "- Load sample data\n",
    "- Create an Banking Agent Flow on Langflow.\n",
    "- Connect the Astra DB Tools to the agent.\n",
    "- Run the Flow through the Langflow API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a22590",
   "metadata": {},
   "source": [
    "# Astra DB NoSQL Tables\n",
    "\n",
    "In the previous steps, we focused on the **Collection** data model — a semi-structured format that allows customers to store and query flexible JSON documents.\n",
    "\n",
    "However, for certain challenges faced by large enterprises, the **Table** model is recommended, especially when applications require characteristics inherited from _Apache Cassandra_, such as:\n",
    "\n",
    "### Low Latency / High Throughput\n",
    "\n",
    "Applications that need to write thousands of records per second or read data within milliseconds — even across multiple terabytes — benefit from Cassandra’s data model, which is intentionally optimized for high-performance reads and writes.\n",
    "\n",
    "### High Availability\n",
    "\n",
    "Applications that cannot afford downtime require data replication across multiple data centers. Every Astra DB instance automatically runs across three availability zones within a cloud region, achieving 99.99% uptime. Optionally, databases can span two (or more) regions, further increasing availability to 99.999%. This replication happens automatically without requiring changes to the application.\n",
    "\n",
    "### Massive Storage with Linear Scalability\n",
    "\n",
    "Astra DB can store terabytes of data while maintaining consistent read and write performance. Thanks to intelligent data partitioning, records are organized in a way that allows Cassandra to scale linearly and efficiently, even as data volume grows.\n",
    "\n",
    "## Astra DB\n",
    "\n",
    "Beyond the Apache Cassandra features, by running applications on DataStax Astra, the companies will also have additional benefits:\n",
    "\n",
    "### Reduced Operational Overhead\n",
    "\n",
    "Astra DB is a fully managed service that alleviates the need for teams to perform operational tasks such as server management, scaling, or maintenance. This allows developers to focus on building features rather than managing the database infrastructure, enhancing productivity.\n",
    "\n",
    "### Multi-Cloud Flexibility\n",
    "\n",
    "Astra DB supports deployment across multiple cloud environments, providing businesses with the flexibility to operate in a hybrid or multi-cloud strategy. This flexibility enhances disaster recovery and ensures better performance based on geographic demands. Currently, users can create databases on AWS, MIcrosoft Azure and GCP in pultiple regions.\n",
    "\n",
    "### Enhanced Security and Compliance\n",
    "\n",
    "With built-in security features and compliance with industry standards (including HIPAA for healthcare), Astra DB provides a secure environment for managing sensitive data, which is critical for regulated industries.\n",
    "\n",
    "# Astra DB — Key Characteristics and Application Fit\n",
    "\n",
    "| Astra DB Characteristic | Application Needs                       | Why It Matters                                                      | Example Use Cases                                                                                                  |\n",
    "| ----------------------- | --------------------------------------- | ------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------ |\n",
    "| **Scaling**             | High Throughput, High Volume, Real-Time | Supports heavy writes and reads at scale                            | AI memory, chatbot sessions, event streaming, IoT, log analytics, time series, transaction systems, feature stores |\n",
    "| **Availability**        | Mission-Critical Operations             | No data loss, always-on availability                                | E-commerce, caching, inventory management, healthcare systems                                                      |\n",
    "| **Distribution**        | Global Presence, Workload Mobility      | Compliance (e.g., GDPR), enhanced customer experience               | Banking, media streaming, logistics, retail                                                                        |\n",
    "| **Cloud Native**        | Managed Services                        | API-first architecture, multi-model support, multi-cloud deployment | Mobile apps, cloud modernization projects                                                                          |\n",
    "| **AI Ready**            | Knowledge Layer Integration             | Vector search, re-ranking, LLM integration                          | Retrieval-Augmented Generation (RAG), AI agents, customer service automation                                       |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7be45b",
   "metadata": {},
   "source": [
    "# Banking use case\n",
    "\n",
    "We will generate a banking statement with transactions. To do that, we will create a table on the the same database from the previous steps and load some sample data.\n",
    "\n",
    "To start, you will need to download the [Secure Connect Bundle](https://docs.datastax.com/en/astra-db-serverless/databases/secure-connect-bundle.html) on the Astra DB Dashboard.\n",
    "\n",
    "<img src=\"./img/scb.png\" alt=\"Secure Connect Bundle\" width=\"600\"/>\n",
    "\n",
    "CLick on the \"Download SCB\" button. Copy the cURL command:\n",
    "\n",
    "<img src=\"./img/scb1.png\" alt=\"Secure Connect Bundle\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc24138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 12323  100 12323    0     0  24218      0 --:--:-- --:--:-- --:--:-- 24210\n"
     ]
    }
   ],
   "source": [
    "# Run the curl command on the line below (add the exclamation mark at the start of the line) to download the secure-connect bundle for the Astra DB instance.\n",
    "# This bundle is used to connect to the Astra DB instance from the Python code.\n",
    "# The bundle contains the necessary certificates and configuration files.\n",
    "!curl -o secure-connect-astra-ibm-demo.zip '<your secure-connect bundle URL>'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bac0b32",
   "metadata": {},
   "source": [
    "You should see the `secure-connect-astra-ibm-demo.zip`file on this folder\n",
    "\n",
    "With the file and environment variables set, lets connect to the DB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11ba21a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from cassandra.query import SimpleStatement, PreparedStatement, BatchStatement\n",
    "from cassandra.cluster import Cluster, PlainTextAuthProvider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c854083a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Astra Token: AstraCS:bf...35ec6\n",
      "Astra Endpoint: ...2.apps.astra.datastax.com\n",
      "Good to go!\n"
     ]
    }
   ],
   "source": [
    "# Make sure the environment variables are set\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "if os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\") is None:\n",
    "    raise ValueError(\"Environment variable ASTRA_DB_APPLICATION_TOKEN not set\")\n",
    "\n",
    "if os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\")[:8] != \"AstraCS:\":\n",
    "    raise ValueError(\n",
    "        \"Environment variable ASTRA_DB_APPLICATION_TOKEN invalid format\")\n",
    "\n",
    "if \".apps.astra.datastax.com\" not in os.getenv(\"ASTRA_DB_API_ENDPOINT\"):\n",
    "    raise ValueError(\"Environment variable ASTRA_DB_API_ENDPOINT invalid\")\n",
    "\n",
    "print(\n",
    "    f'Astra Token: {os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\")[:10]}...{os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\")[-5:]}')\n",
    "print(f'Astra Endpoint: ...{os.getenv(\"ASTRA_DB_API_ENDPOINT\")[-25:]}')\n",
    "print(\"Good to go!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d73e664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(keyspace_name='default_keyspace', table_name='banking_knowledge_layer', additional_write_policy='99p', bloom_filter_fp_chance=0.01, caching=OrderedMapSerializedKey([('keys', 'ALL'), ('rows_per_partition', 'NONE')]), cdc=None, comment='{\"collection\":{\"name\":\"banking_knowledge_layer\",\"schema_version\":1,\"options\":{\"vector\":{\"dimension\":1024,\"metric\":\"cosine\",\"sourceModel\":\"OTHER\",\"service\":{\"provider\":\"nvidia\",\"modelName\":\"NV-Embed-QA\"}},\"defaultId\":{\"type\":\"\"},\"lexical\":{\"enabled\":true,\"analyzer\":\"standard\"},\"rerank\":{\"enabled\":true,\"service\":{\"provider\":\"nvidia\",\"modelName\":\"nvidia/llama-3.2-nv-rerankqa-1b-v2\",\"authentication\":null,\"parameters\":null}}}}}', compaction=OrderedMapSerializedKey([('class', 'org.apache.cassandra.db.compaction.UnifiedCompactionStrategy')]), compression=OrderedMapSerializedKey([('chunk_length_in_kb', '16'), ('class', 'org.apache.cassandra.io.compress.LZ4Compressor')]), crc_check_chance=1.0, dclocal_read_repair_chance=0.0, default_time_to_live=0, extensions=OrderedMapSerializedKey([]), flags=SortedSet(['compound']), gc_grace_seconds=864000, id=UUID('a449f090-211e-11f0-8bfb-29096b779175'), max_index_interval=2048, memtable=OrderedMapSerializedKey([]), memtable_flush_period_in_ms=0, min_index_interval=128, nodesync=None, read_repair='BLOCKING', read_repair_chance=0.0, speculative_retry='99p')\n"
     ]
    }
   ],
   "source": [
    "# create a connection to the Astra DB\n",
    "cluster = Cluster(\n",
    "    cloud={\n",
    "        \"secure_connect_bundle\": \"./secure-connect-astra-ibm-demo.zip\",\n",
    "    },\n",
    "    auth_provider=PlainTextAuthProvider(\n",
    "        \"token\",\n",
    "        os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\"),\n",
    "    ),\n",
    ")\n",
    "session = cluster.connect(\"default_keyspace\")\n",
    "\n",
    "# Execute a simple query to test the connection\n",
    "rs = session.execute(\"SELECT * FROM system_schema.tables where keyspace_name = 'default_keyspace' limit 1\")\n",
    "print(rs.one())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb53d3b",
   "metadata": {},
   "source": [
    "Before creating the table, a summary about the Cassandra Data Modeling:\n",
    "\n",
    "<img src=\"./img/data_modeling.png\" alt=\"Data Modeling\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "853b8c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table transactions_by_month created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Lets create a table to store transactions by month\n",
    "\n",
    "create_table = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS transactions_by_month (\n",
    "    account_id UUID,\n",
    "    year_month TEXT,                -- Format: 'YYYYMM', e.g., '202504'\n",
    "    transaction_timestamp TIMESTAMP,\n",
    "    transaction_id UUID,\n",
    "    amount DECIMAL,\n",
    "    currency TEXT,\n",
    "    channel TEXT,                  -- e.g., 'app', 'credit_card'\n",
    "    location TEXT,                 -- e.g., 'Geo: -23.5,-46.6'\n",
    "    merchant TEXT,\n",
    "    description TEXT,\n",
    "    balance_after DECIMAL,         -- NEW: balance after this transaction\n",
    "\n",
    "    PRIMARY KEY ((account_id, year_month), transaction_timestamp, transaction_id)\n",
    ") WITH CLUSTERING ORDER BY (transaction_timestamp DESC, transaction_id ASC);\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "session.execute(create_table)\n",
    "print(\"Table transactions_by_month created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fe404c",
   "metadata": {},
   "source": [
    "Note the PRIMARY KEY definition:\n",
    "\n",
    "```\n",
    "PRIMARY KEY ((account_id, year_month), transaction_timestamp, transaction_id)\n",
    "```\n",
    "\n",
    "The combined account_id and year_month are the partition key\n",
    "transaction_timestamp and transaction_id are the clustering keys\n",
    "\n",
    "This allows us to query transactions by account_id and year_month, and sort them by transaction_timestamp and transaction_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a413b58",
   "metadata": {},
   "source": [
    "### Astra DB CQL Console\n",
    "\n",
    "The Astra DB CQL Console is a web-based tool that allows you to interact with the database using the CQL (Cassandra Query Language). It provides a user-friendly interface for executing queries, managing tables, and monitoring the database.\n",
    "\n",
    "To access the CQL Console, navigate to the Astra DB Dashboard and click on the \"CQL Console\" button.\n",
    "\n",
    "<img src=\"./img/console.png\" alt=\"Console\" width=\"600\"/>\n",
    "\n",
    "The DESCRIBE command is used to get the table schema.\n",
    "\n",
    "```\n",
    "USE default_keyspace;\n",
    "DESCRIBE transactions_by_month;\n",
    "```\n",
    "\n",
    "<img src=\"./img/console1.png\" alt=\"Console\" width=\"600\"/>\n",
    "\n",
    "Now, lets load some data into the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1d161e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully inserted 50 transactions for 0a662701-cb5d-4253-834c-b28233a832fa customer\n",
      "Successfully inserted 50 transactions for a93236cc-2495-479b-8154-4eced1c1df87 customer\n",
      "Successfully inserted 50 transactions for 7049e58a-36ab-44e6-8a59-66dd2bf40fff customer\n",
      "Successfully inserted 50 transactions for 67c3b9fb-3c76-4b4d-8a69-0905ce046388 customer\n",
      "Successfully inserted 50 transactions for 28d3991d-3e61-41fb-921f-4b247156acdd customer\n",
      "Successfully inserted 50 transactions for 1ed051a5-d1db-4909-9c94-3fec92abf00c customer\n",
      "Successfully inserted 50 transactions for c45b4f5f-5c7b-41b3-b969-5cf53476e2f7 customer\n",
      "Successfully inserted 50 transactions for a34fd963-648b-4730-9069-38c7dab512bb customer\n",
      "Successfully inserted 50 transactions for 0ba7bedf-94cd-409d-bed7-123715e884e1 customer\n",
      "Successfully inserted 50 transactions for aabdf051-bc6b-4c8a-820f-cfa094ba78ad customer\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to generate transactions\n",
    "import uuid\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "fake = Faker()\n",
    "start_date = datetime(2025, 6, 1)\n",
    "end_date = datetime(2025, 7, 1)\n",
    "# Define possible channels and categories\n",
    "channels = ['mobile_app', 'web_banking', 'atm', 'branch', 'credit_card']\n",
    "categories = ['groceries', 'dining', 'transportation',\n",
    "              'entertainment', 'shopping', 'utilities', 'healthcare', 'travel']\n",
    "\n",
    "# Prepare the insert statement\n",
    "cmd = session.prepare(\"\"\"INSERT INTO transactions_by_month (\n",
    "    account_id, \n",
    "    year_month, \n",
    "    transaction_timestamp, \n",
    "    transaction_id, \n",
    "    amount, \n",
    "    currency, \n",
    "    channel, \n",
    "    location, \n",
    "    merchant, \n",
    "    description, \n",
    "    balance_after) VALUES (\n",
    "    :account_id, \n",
    "    :year_month, \n",
    "    :transaction_timestamp, \n",
    "    :transaction_id, \n",
    "    :amount, \n",
    "    :currency, \n",
    "    :channel, \n",
    "    :location, \n",
    "    :merchant, \n",
    "    :description, \n",
    "    :balance_after)\"\"\")\n",
    "\n",
    "# Prepare the batch statement\n",
    "batch = BatchStatement()\n",
    "\n",
    "# Generate 50 transactions for each customer\n",
    "batch = BatchStatement()\n",
    "customers = [uuid.uuid4() for _ in range(10)]\n",
    "merchants = ['Walmart', 'Target', 'Amazon', 'Starbucks', 'McDonalds', 'Uber', 'Lyft', 'Netflix', 'Spotify', 'Apple Store']\n",
    "\n",
    "for customer in customers:\n",
    "    account_id = uuid.uuid4() \n",
    "    year_month = '202506'  # June 2025\n",
    "    balance = random.uniform(1000.00, 10000.00)  # Starting balance\n",
    "    current_date = start_date\n",
    "    time_increment = (end_date - start_date) / 60  # Divide the month into 50 equal intervals\n",
    "    \n",
    "    \n",
    "    for _ in range(50):\n",
    "        transaction_id = uuid.uuid4()\n",
    "        transaction_timestamp = current_date\n",
    "        current_date += time_increment\n",
    "        amount = round(random.uniform(-500.00, 500.00), 2)\n",
    "        balance += amount\n",
    "        merchant = random.choice(merchants)\n",
    "        \n",
    "        batch.add(cmd, {\n",
    "            'account_id': account_id,\n",
    "            'year_month': year_month,\n",
    "            'transaction_timestamp': transaction_timestamp,\n",
    "            'transaction_id': transaction_id,\n",
    "            'amount': amount,\n",
    "            'currency': 'USD',\n",
    "            'channel': random.choice(channels),\n",
    "            'location': 'Geo: -23.5,-46.6',\n",
    "            'merchant': random.choice(merchants),\n",
    "            'description': f\"{random.choice(merchants)} - {random.choice(categories)}\",\n",
    "            'balance_after': balance\n",
    "        })\n",
    "\n",
    "    # Execute the batch\n",
    "    session.execute(batch)\n",
    "    print(f\"Successfully inserted {len(batch) } transactions for {account_id} customer\")\n",
    "    batch.clear()\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91dbb54c",
   "metadata": {},
   "source": [
    "Check the result on the CQL Console.\n",
    "\n",
    "```\n",
    "SELECT * FROM default_keyspace.transactions_by_month LIMIT 1;\n",
    "```\n",
    "\n",
    "<img src=\"./img/console2.png\" alt=\"Console\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c339b8",
   "metadata": {},
   "source": [
    "# Langflow Agent\n",
    "\n",
    "We will create an AI Agent that access the table with banking transactions.\n",
    "\n",
    "The flow is available on this repo (file: Part_III - Langflow Agent with NoSQL data from Astra DB.json). \n",
    "\n",
    "After accessing Langflow, create a blank flow:\n",
    "\n",
    "<img src=\"./img/lf_blank_flow.png\" alt=\"Console\" width=\"600\"/>\n",
    "\n",
    "Then, you can drag the json file to the canvas or use the import option on the menu:\n",
    "\n",
    "<img src=\"./img/lf_import.png\" alt=\"Console\" width=\"600\"/>\n",
    "\n",
    "After import, your flow will be something like this:\n",
    "\n",
    "<img src=\"./img/lf_agent.png\" alt=\"Console\" width=\"600\"/>\n",
    "\n",
    "## Customizing the flow.\n",
    "\n",
    "### Text Input\n",
    "\n",
    "Change the content of the component \"Text Input\" with a account_id stored on yout database. Execute the next cell to retriev this value:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a34b639a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(account_id=UUID('c45b4f5f-5c7b-41b3-b969-5cf53476e2f7'))\n"
     ]
    }
   ],
   "source": [
    "rs = session.execute(\"SELECT account_id FROM default_keyspace.transactions_by_month limit 1\")\n",
    "print(rs.one())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc54105",
   "metadata": {},
   "source": [
    "Click on the edit button and input the ID.\n",
    "\n",
    "<img src=\"./img/lf_agent_edit_acc.png\" alt=\"Console\" width=\"600\"/>\n",
    "\n",
    "### Astra DB CQL\n",
    "\n",
    "On the \"Astra DB CQL\" component, click on the options for \"Astra DB Application Token\", then select \"+ Add New Variable\":\n",
    "\n",
    "<img src=\"./img/lf_agent_var.png\" alt=\"Console\" width=\"300\"/>\n",
    "\n",
    "Then, create a variable named \"ASTRA_IBM_TOKEN\" and fill the value with \"ASTRA_DB_APPLICATION_TOKEN\" available on your .env file and save the variable.\n",
    "\n",
    "<img src=\"./img/lf_agent_var2.png\" alt=\"Console\" width=\"300\"/>\n",
    "\n",
    "Do the same with the API Endpoint. Create a variable named \"ASTRA_IBM_API\" and fill the value with \"ASTRA_DB_API_ENDPOINT\" available on your .env file and save the variable.\n",
    "\n",
    "Now, click on the button \"Tool Parameters\". These are the parameters that the LLM will fill in order to run the tool.\n",
    "\n",
    "<img src=\"./img/lf_agent_tool_param.png\" alt=\"Console\" width=\"600\"/>\n",
    "\n",
    "### Agent\n",
    "\n",
    "As we are using the Open AI model to run our agent, it is needed define the Open AI API KEY the agent will use. \n",
    "\n",
    "Execute the same procedure for creating a variable named \"OPENAI_API_KEY\" to save your key and select it on the component.\n",
    "\n",
    "## Running the flow\n",
    "\n",
    "Click on the ```Playground``` button and enter the question:\n",
    "\n",
    "> How much did I spend between June 15 and 25, 2025?\n",
    "\n",
    "Your result should be something like this (but the numbers and dates may be different):\n",
    "\n",
    "<img src=\"./img/lf_agent_run1.png\" alt=\"Console\" width=\"600\"/>\n",
    "\n",
    "Now, click on the \"detail\" button and inspect the execution.\n",
    "\n",
    "The \"Input\" section shows how the LLM filled the tool parameters:\n",
    "\n",
    "<img src=\"./img/lf_agent_run2.png\" alt=\"Console\" width=\"600\"/>\n",
    "\n",
    "The \"Output\" section shows the data returned from the tool (Astra DB) to the LLM:\n",
    "\n",
    "<img src=\"./img/lf_agent_run3.png\" alt=\"Console\" width=\"600\"/>\n",
    "\n",
    "Then, the LLM had real time context to answer the question:\n",
    "\n",
    "<img src=\"./img/lf_agent_run4.png\" alt=\"Console\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25e7c3b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76212a9b",
   "metadata": {},
   "source": [
    "# Recap\n",
    "\n",
    "In this exercise, you learned:\n",
    "\n",
    "**Using Astra:**\n",
    "- The main features available for companies\n",
    "- Common use cases\n",
    "- How to connect to Astra\n",
    "- How to create tables in Astra\n",
    "- How to use the Astra DB Console\n",
    "- How to load data into Astra\n",
    "\n",
    "**Using Langflow:**\n",
    "- How to import flows\n",
    "- How to customize flow execution\n",
    "- How to configure the Astra DB Tool\n",
    "- How to create and reuse variables\n",
    "- How to inspect agent execution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e4689b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
