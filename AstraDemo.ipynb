{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IBM & DataStax Demo - Banking AI Agent\n",
    "\n",
    "## Before start\n",
    "\n",
    "What you will need:\n",
    "\n",
    "- Install dependencies (check the README.md)\n",
    "- An account on DataStax Astra (Part I)\n",
    "- A API Key from Watsonx.AI or OpenAI\n",
    "\n",
    "## Part I - Astra Setup\n",
    "\n",
    "- Create an account on DataStax Astra.\n",
    "- Create a Database\n",
    "- Create a collection with Vectorize (NVIDIA model)\n",
    "- Load the Astra collection with a document\n",
    "\n",
    "## Part II - Langflow RAG\n",
    "\n",
    "- Create a Langflow RAG flow and connect to Astra\n",
    "- Activate the NVIDIA reranker\n",
    "- Run the Flow through the Langflow API\n",
    "\n",
    "## Part III - Agents and NoSQL\n",
    "\n",
    "- Create a CQL table to store banking transactions\n",
    "- Load sample data\n",
    "- Create an Banking Agent Flow on Langflow.\n",
    "- Connect the Astra DB Tools to the agent.\n",
    "- Run the Flow through the Langflow API\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing dependencies\n",
    "\n",
    "Check the [README.md](./README.md) to set up your enviroment before startinge the execution of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the DataStax Astra Account\n",
    "\n",
    ">INFO: On DataStax Astra, every user receives $25 in credits *EVERY MONTH* to run Astra DB, Astra Streaming and Langflow.\n",
    "\n",
    "To start using the platform, access [astra.datastax.com] and click on the \"Sign Up\" link to start the registration.\n",
    "\n",
    "![My Image](img/signup.png)\n",
    "\n",
    "html\n",
    "\n",
    "<img src=\"img/signup.png\" alt=\"SSign Up Page\" width=\"600\"/>\n",
    "\n",
    "After the Sign Up process, you should be able to login in to the Astra Dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I - Astra DB Setup\n",
    "\n",
    "## Creating a Database\n",
    "\n",
    "After logging in on Astra Dashboard, click on the \"Create Database\" button.\n",
    "\n",
    "<img src=\"img/dashboard.png\" alt=\"Start Database creation\" width=\"600\"/>\n",
    "\n",
    "On the Create Database screen, fill\n",
    "\n",
    "- Deployment Type: Serverless (Vector)\n",
    "- Provider: AWS\n",
    "- Region: us-east-2\n",
    "\n",
    "<img src=\"img/create_db.png\" alt=\"DB Creation\" width=\"600\"/>\n",
    "\n",
    "> INFO: It is possible to create DBs on AWS, Azure and GCP. To check all available regions, check our [documentation](https://docs.datastax.com/en/astra-db-serverless/databases/regions.html)\n",
    "\n",
    "After 2 or 3 minutes, your database will be ready to start using it.\n",
    "\n",
    "<img src=\"img/db_created.png\" alt=\"DB Created\" width=\"600\"/>\n",
    "\n",
    "More info available [here](https://docs.datastax.com/en/astra-db-serverless/databases/create-database.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Collection\n",
    "\n",
    "> INFO: Astra DB can store __collections__ and __tables__\n",
    ">\n",
    "> [__Collections__](https://docs.datastax.com/en/astra-db-serverless/api-reference/collections.html) are used to store JSON documents with a semi structured data model. It is compatible with Mongo DB and [MongooseJS](https://docs.datastax.com/en/astra-db-serverless/integrations/data-api-with-mongoosejs.html). \n",
    ">\n",
    "> [__Tables__](https://docs.datastax.com/en/astra-db-serverless/cql/develop-with-cql.html) are used to store transactional data that requires high throughput and low latencies. Due to its data model it is possible to achieve tens of thousands operations per second. \n",
    ">\n",
    "> Both models are compatible with __Vector Search__\n",
    "\n",
    "\n",
    "On the DB Dashboard, click on __\"Data Explorer\"__ and then click on __\"Create Collection +\"__\n",
    "\n",
    "<img src=\"img/start_create_collection.png\" alt=\"Start collection creation\" width=\"600\"/>\n",
    "\n",
    "The screen for the collection creation should be filled with:\n",
    "\n",
    "- Collection name: banking_knowledge_layer\n",
    "- Vector-enabled collection: Activated\n",
    "- Embedding generation method: NVIDIA (The embedding model and dimension will be filled automatically)\n",
    "- Similarity Metric: Cosine (Dot Product and Euclidean are additional options)\n",
    "\n",
    "<img src=\"img/create_collection.png\" alt=\"Create collection\" width=\"600\"/>\n",
    "\n",
    "\n",
    "> ### Vectorize\n",
    "> \n",
    "> \n",
    "> When creating a collection, you can automate the embedding generation process using [__Vectorize__](https://docs.datastax.com/en/astra-db-serverless/databases/embedding-generation.html).\n",
    ">\n",
    "> In this example, we're using NVIDIA models provided by DataStax. However, you can also integrate with other model providers such as OpenAI, Azure OpenAI, Hugging Face, and more.\n",
    "> \n",
    "> With this setup, all embedding generation—whether during data loading or querying—is seamlessly handled at the database layer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data.\n",
    "\n",
    "There are multiple ways to load data into Astra. For this part of demo, we'll use __LangChain__ to showcase the developer experience we offer for users who want full control over the entire process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the token and API Endpoint\n",
    "\n",
    "Start by copying the \"_env_sample\" file to \".env\" file. We will store the Astra token information on the env file.\n",
    "\n",
    "On the Astra Dashboard, access the db \"astra_ibm_demo\", click on the \"Overview\" tab and find the \"Database Details\" on the right side of the screen.\n",
    "\n",
    "<img src=\"img/token.png\" alt=\"Token\" width=\"600\"/>\n",
    "\n",
    "Copy the API Endpoint and save it to the \".env\" file.\n",
    "\n",
    "On the \"Application Tokens\" block, click on \"Generate Token\". It will open another block to generate the token. \n",
    "\n",
    "You can give some name to the token:\n",
    "\n",
    "<img src=\"./img/generate_token.png\" alt=\"Token\" width=\"600\"/>\n",
    "\n",
    "The token will be created. Click on the \"Copy\" button and paste the value on your \".env\" file.\n",
    "\n",
    "Your \".env\" file will be looking like this:\n",
    "\n",
    "```bash\n",
    "ASTRA_DB_APPLICATION_TOKEN=\"<your token>\"\n",
    "ASTRA_DB_API_ENDPOINT=\"<your db endpoint>\"\n",
    "IBM_WATSON_TOKEN=\"\"\n",
    "OPENAI_API_TOKEN=\n",
    "```\n",
    "\n",
    "Let's check if the environment variables are created:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Astra Token: AstraCS:bf...35ec6\n",
      "Astra Endpoint: https://0df6bdb1-a6ca-4420-ba2e-f28550b3d178-us-east-2.apps.astra.datastax.com\n",
      "Good to go!\n"
     ]
    }
   ],
   "source": [
    "#Make sure the environment variables are set\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "if os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\") is None:\n",
    "    raise ValueError(\"Environment variable ASTRA_DB_APPLICATION_TOKEN not set\")\n",
    "\n",
    "if os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\")[:8] != \"AstraCS:\":\n",
    "    raise ValueError(\"Environment variable ASTRA_DB_APPLICATION_TOKEN invalid format\")\n",
    "\n",
    "if \".apps.astra.datastax.com\" not in os.getenv(\"ASTRA_DB_API_ENDPOINT\"):\n",
    "    raise ValueError(\"Environment variable ASTRA_DB_API_ENDPOINT invalid\")\n",
    "\n",
    "print(f'Astra Token: {os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\")[:10]}...{os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\")[-5:]}')\n",
    "print(f'Astra Endpoint: {os.getenv(\"ASTRA_DB_API_ENDPOINT\")}')\n",
    "print(\"Good to go!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data load\n",
    "\n",
    "We will load public files from the Chase bank. We will use this documents as the source for questions answering and Agentic RAG.\n",
    "\n",
    "The files are available on the ```docs``` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "from langchain_astradb import AstraDBVectorStore\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the AstraDBVectorStore\n",
    "from langchain_astradb.utils.astradb import HybridSearchMode\n",
    "vector_store = AstraDBVectorStore(\n",
    "    collection_name=\"banking_knowledge_layer\",\n",
    "    api_endpoint=os.getenv(\"ASTRA_DB_API_ENDPOINT\"),\n",
    "    token=os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\"),\n",
    "    autodetect_collection=True,\n",
    "    hybrid_search=HybridSearchMode.OFF\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning up the collection to start fresh\n",
    "# WARNING: This will delete all documents in the collection\n",
    "vector_store.clear() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 852 chunks from the directory.\n",
      "Added 852 chunks to the vector store.\n"
     ]
    }
   ],
   "source": [
    "# Loading the documents from the specified directory\n",
    "from langchain_community.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Load the documents from the specified directory\n",
    "loader = DirectoryLoader(\n",
    "    \"./docs\",\n",
    "    glob=\"**/*.pdf\",\n",
    "    loader_cls=PyPDFLoader\n",
    ")\n",
    "\n",
    "# Split the documents into smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=80,\n",
    ")\n",
    "documents = loader.load()\n",
    "texts = text_splitter.split_documents(documents)\n",
    "print(f\"Loaded {len(texts)} chunks from the directory.\")\n",
    "\n",
    "# Add the documents to the vector store\n",
    "vector_store.add_documents(texts)\n",
    "print(f\"Added {len(texts)} chunks to the vector store.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying data.\n",
    "\n",
    "With the knowledge base loaded, we can begin querying the vector store to retrieve passages relevant to a given question. This is the foundation of [RAG (Retrieval-Augmented Generation)](https://www.datastax.com/blog/what-is-rag-retrieval-augmented-generation).\n",
    "\n",
    "Astra DB is capable of storing [millions of embeddings](https://www.datastax.com/press-release/wikimedia-deutschland-launches-ai-knowledge-project-in-collaboration-with-datastax-built-with-nvidia-ai). However, to achieve optimal performance and relevance, it’s a best practice to filter results using metadata whenever possible.\n",
    "\n",
    "In the next steps, we’ll apply a metadata filter to target a specific document.\n",
    "\n",
    "In the first query, we will run a query and return the top 3 most relevant chunks using only the vector search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Guide to Benefits\n",
      "Subject: BGC10979\n",
      "Page Content: repatriate the remains. All costs are Your responsibility.\n",
      "• Emergency Ticket Replacement helps You through Your carrier’s \n",
      "lost ticket reimbursement process and assists in the delivery of a \n",
      "replacement ticket to You, should You lose Your ticket. All costs \n",
      "are Your responsibility.\n",
      "• Lost Luggage Locator Service helps You through the Common \n",
      "Carrier’s claim procedures or can arrange shipment of \n",
      "replacement items if an airline or Common Carrier loses Your\n",
      "--------------------------------------------------------------------------------\n",
      "Title: Guide to Benefits\n",
      "Subject: Guide\n",
      "Page Content: repatriate the remains. All costs are Your responsibility.\n",
      "•  Emergency Ticket Replacement helps You through Your carrier’s \n",
      "lost ticket reimbursement process and assists in the delivery of a \n",
      "replacement ticket to You, should You lose Your ticket. All costs are \n",
      "Your responsibility.\n",
      "•  Lost Luggage Locator Service helps You through the Common \n",
      "Carrier’s claim procedures or can arrange shipment of replacement \n",
      "items if an airline or Common Carrier loses Your checked luggage.\n",
      "--------------------------------------------------------------------------------\n",
      "Title: Guide to Benefits\n",
      "Subject: Guide\n",
      "Page Content: 11\n",
      "If you're outside of the US, call collect at 1-804-281-5772\n",
      "You are also eligible to receive reimbursement for the cost of an \n",
      "economy airfare ticket if Your original ticket(s) cannot be used for Your \n",
      "return flight. In addition, you are eligible to receive reimbursement \n",
      "for the cost of an economy airfare ticket to return an accompanying \n",
      "minor to his/her residence, when applicable. In exchange for this \n",
      "service, any unused return ticket(s) must be turned over to the Benefit\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Lets disable the hybrid search for this example\n",
    "# and use the default similarity search\n",
    "# to retrieve the documents\n",
    "vector_store = AstraDBVectorStore(\n",
    "    collection_name=\"banking_knowledge_layer\",\n",
    "    api_endpoint=os.getenv(\"ASTRA_DB_API_ENDPOINT\"),\n",
    "    token=os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\"),\n",
    "    autodetect_collection=True,\n",
    "    hybrid_search=HybridSearchMode.OFF\n",
    ")\n",
    "docs = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\n",
    "        \"filter\": {\"source\": \"docs/BGC10981_SapphireReserve_VisaInfinite.pdf\"},\n",
    "        \"k\": 3\n",
    "    }\n",
    ").invoke(\"Can I refund a lost ticket lost\")\n",
    "\n",
    "# Create a DataFrame to display the docs in a table format\n",
    "for doc in docs:    \n",
    "    print(f\"Title: {doc.metadata['title']}\")\n",
    "    print(f\"Subject: {doc.metadata['subject']}\")\n",
    "    print(f\"Page Content: {doc.page_content}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are ok, but the returned chunks don't directly answer the question.\n",
    "\n",
    "Let’s enable reranking to improve the quality and relevance of the responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrated Reranking\n",
    "\n",
    "When developing a RAG (Retrieval-Augmented Generation) application, the results retrieved from Astra may sometimes require refinement to enhance accuracy.\n",
    "\n",
    "Fortunately, [Astra has reranking built into its API](https://docs.datastax.com/en/astra-db-serverless/api-reference/document-methods/find-and-rerank.html), allowing us to retrieve reranked documents by default—no additional configuration needed.\n",
    "\n",
    "> INFO: Astra DB Hybrid Search is enhanced with server-side reranking using the NVIDIA NeMo Retriever reranking microservices - built with NVIDIA NIM, part of the NVIDIA AI Enterprise software.\n",
    ">\n",
    "> Check this [blog post](https://www.datastax.com/blog/introducing-astra-db-hybrid-search) for more information\n",
    "\n",
    "Let’s run the same query again and compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuel.matioli/work/astra-ibm-demo-2/venv/lib/python3.11/site-packages/langchain_astradb/vectorstores.py:2677: BetaFeatureWarning: Method 'Collection.find_and_rerank' is in beta and might undergo signature or behaviour changes in the future.\n",
      "  hybrid_reranked_results = self.astra_env.collection.find_and_rerank(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Guide to Benefits\n",
      "Subject: Guide\n",
      "Page Content: 41\n",
      "If you're outside of the US, call collect at 1-804-281-5772\n",
      "necessary medical treatment, to the airport, terminal or station of \n",
      "departure, and/or between the arrival airport, terminal or station \n",
      "and Your residence. This does not include transportation in vehicles \n",
      "operated by a medical facility or specifically designed to transport sick \n",
      "or injured individuals.\n",
      "If You are forced to temporarily postpone a Trip due to a loss and a \n",
      "new departure date is set, We will reimburse for the prepaid unused\n",
      "--------------------------------------------------------------------------------\n",
      "Title: Guide to Benefits\n",
      "Subject: Guide\n",
      "Page Content: repatriate the remains. All costs are Your responsibility.\n",
      "•  Emergency Ticket Replacement helps You through Your carrier’s \n",
      "lost ticket reimbursement process and assists in the delivery of a \n",
      "replacement ticket to You, should You lose Your ticket. All costs are \n",
      "Your responsibility.\n",
      "•  Lost Luggage Locator Service helps You through the Common \n",
      "Carrier’s claim procedures or can arrange shipment of replacement \n",
      "items if an airline or Common Carrier loses Your checked luggage.\n",
      "--------------------------------------------------------------------------------\n",
      "Title: Guide to Benefits\n",
      "Subject: Guide\n",
      "Page Content: •  Any loss due to the voluntary surrender of unused vouchers, tickets, \n",
      "credits, coupons, or travel privileges available to You from the Travel \n",
      "Supplier prior to their expiration date\n",
      "•  Travel arrangements that are scheduled to take place after the \n",
      "twenty–sixth (26th) week of pregnancy; or when any multiple \n",
      "pregnancy, with or without complications, occurs prior to the \n",
      "initial deposit date or booking date of the Trip; or any pregnancy \n",
      "associated with an assisted reproductive program, such as\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Lets recreate the vector store with hybrid search enabled\n",
    "vector_store = AstraDBVectorStore(\n",
    "    collection_name=\"banking_knowledge_layer\",\n",
    "    api_endpoint=os.getenv(\"ASTRA_DB_API_ENDPOINT\"),\n",
    "    token=os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\"),\n",
    "    autodetect_collection=True,\n",
    "    hybrid_search=HybridSearchMode.ON\n",
    ")\n",
    "\n",
    "docs_reranked = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\n",
    "        \"filter\": {\"source\": \"docs/BGC10981_SapphireReserve_VisaInfinite.pdf\"},\n",
    "        \"k\": 3\n",
    "    }\n",
    ").invoke(\"Can I refund a lost ticket?\")\n",
    "\n",
    "# Create a DataFrame to display the docs in a table format\n",
    "for doc in docs_reranked:    \n",
    "    print(f\"Title: {doc.metadata['title']}\")\n",
    "    print(f\"Subject: {doc.metadata['subject']}\")\n",
    "    print(f\"Page Content: {doc.page_content}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the results are better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Lexical Search\n",
    "\n",
    "While semantic search is powerful for understanding the meaning behind queries, there are situations where we need more control—such as filtering by specific keywords, brand names, acronyms, or exact phrases. This is where lexical search becomes useful.\n",
    "\n",
    "Astra DB supports lexical filtering by allowing the use of the $sort clause, which can be combined with vector search to refine results based on exact word matches. This hybrid approach ensures that your application can handle both semantic relevance and precise keyword filtering.\n",
    "\n",
    "In the following example, we’ll apply lexical filtering to narrow down results to those containing specific terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuel.matioli/work/astra-ibm-demo-2/venv/lib/python3.11/site-packages/langchain_astradb/vectorstores.py:2677: BetaFeatureWarning: Method 'Collection.find_and_rerank' is in beta and might undergo signature or behaviour changes in the future.\n",
      "  hybrid_reranked_results = self.astra_env.collection.find_and_rerank(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Guide to Benefits\n",
      "Subject: Guide\n",
      "Page Content: 41\n",
      "If you're outside of the US, call collect at 1-804-281-5772\n",
      "necessary medical treatment, to the airport, terminal or station of \n",
      "departure, and/or between the arrival airport, terminal or station \n",
      "and Your residence. This does not include transportation in vehicles \n",
      "operated by a medical facility or specifically designed to transport sick \n",
      "or injured individuals.\n",
      "If You are forced to temporarily postpone a Trip due to a loss and a \n",
      "new departure date is set, We will reimburse for the prepaid unused\n",
      "--------------------------------------------------------------------------------\n",
      "Title: Guide to Benefits\n",
      "Subject: Guide\n",
      "Page Content: repatriate the remains. All costs are Your responsibility.\n",
      "•  Emergency Ticket Replacement helps You through Your carrier’s \n",
      "lost ticket reimbursement process and assists in the delivery of a \n",
      "replacement ticket to You, should You lose Your ticket. All costs are \n",
      "Your responsibility.\n",
      "•  Lost Luggage Locator Service helps You through the Common \n",
      "Carrier’s claim procedures or can arrange shipment of replacement \n",
      "items if an airline or Common Carrier loses Your checked luggage.\n",
      "--------------------------------------------------------------------------------\n",
      "Title: Guide to Benefits\n",
      "Subject: Guide\n",
      "Page Content: •  Any loss due to the voluntary surrender of unused vouchers, tickets, \n",
      "credits, coupons, or travel privileges available to You from the Travel \n",
      "Supplier prior to their expiration date\n",
      "•  Travel arrangements that are scheduled to take place after the \n",
      "twenty–sixth (26th) week of pregnancy; or when any multiple \n",
      "pregnancy, with or without complications, occurs prior to the \n",
      "initial deposit date or booking date of the Trip; or any pregnancy \n",
      "associated with an assisted reproductive program, such as\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Lets recreate the vector store with hybrid search enabled\n",
    "vector_store = AstraDBVectorStore(\n",
    "    collection_name=\"banking_knowledge_layer\",\n",
    "    api_endpoint=os.getenv(\"ASTRA_DB_API_ENDPOINT\"),\n",
    "    token=os.getenv(\"ASTRA_DB_APPLICATION_TOKEN\"),\n",
    "    autodetect_collection=True,\n",
    "    hybrid_search=HybridSearchMode.ON\n",
    ")\n",
    "\n",
    "docs_reranked_hybrid = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\n",
    "        \"filter\": {\"source\": \"docs/BGC10981_SapphireReserve_VisaInfinite.pdf\"},\n",
    "        \"k\": 3,\n",
    "        \"$sort\": {\"$hybrid\": \"A tree on a hill\"}\n",
    "    }\n",
    ").invoke(\"Can I refund a lost ticket?\")\n",
    "\n",
    "for doc in docs_reranked_hybrid:    \n",
    "    print(f\"Title: {doc.metadata['title']}\")\n",
    "    print(f\"Subject: {doc.metadata['subject']}\")\n",
    "    print(f\"Page Content: {doc.page_content}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
